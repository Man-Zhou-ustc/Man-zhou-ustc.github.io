
<!DOCTYPE html>
<!-- saved from url=(0040)http://artemsheludko.pw/flexible-jekyll/ -->
<html lang="en">

<!-- Add jQuery library -->
<script type="text/javascript" src="lib/jquery-1.8.2.min.js"></script>
<!-- Add mousewheel plugin (this is optional) -->
<script type="text/javascript" src="lib/jquery.mousewheel-3.0.6.pack.js"></script>
<!-- Add fancyBox main JS and CSS files -->
<script type="text/javascript" src="source/jquery.fancybox.js?v=2.1.3"></script>
<link rel="stylesheet" type="text/css" href="source/jquery.fancybox.css?v=2.1.2" media="screen" />

<!-- javascript function-->
<script type="text/javascript">
  $(document).ready(function() {
    $('.fancybox').fancybox();
    $(".fancybox-effects-c").fancybox({
      wrapCSS    : 'fancybox-custom',
      closeClick : true,
      openEffect : 'none',
      helpers : {
        title : {
          type : 'inside'
        },
        overlay : {
          css : {
            'background' : 'rgba(238,238,238,0.85)'
          }
        }
      }
    });
  });
</script>
<script type="text/javascript">
  function display(id){  
      var traget=document.getElementById(id);  
      if(traget.style.display=="none"){  
          traget.style.display="";  
      }else{  
          traget.style.display="none";  
    }  
 }  
</script>

	

	
<head>
	
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1833684faf5f254c1bb31386c5780c57";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Man Zhou-周满</title>
        <link rel="shortcut icon" href="img/zm.jpg"/>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
	<meta name="keywords" content="Man Zhou, University of Science and Technology of China"> 
	<meta name="description" content="Man Zhou's home page">
	<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
	<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
	<link rel="stylesheet" href="./css/jemdoc.css">
	<title>Man Zhou, University of Science and Technology of China</title>
</head>

<body>
 <div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/manman1995" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250"
 style="fill:#0000FF; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z">
 </path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,
 87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
 <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 
 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,
 77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,
 116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>
 <style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,
 60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px)
 {.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
	
	
	
	
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Man Zhou &nbsp 周满 </h1><h1>
				</h1></div>

				<h3> Research Fellow </h3>
				<p>
					S-Lab,<br>
					Nanyang Technological University, <br>
					Singapore <br>
					<br>
					Email: manman<strong>@</strong>mail<strong>.</strong>ustc<strong>.</strong>edu<strong>.</strong>cn;
				        <br>
					Email: manzhountu<strong>@</strong>gmail<strong>.</strong>com; 
					  <br>
					<h3> Wechat (微信): Zm2903256411 </h3>
					
				       <h3> 欢迎合作与探讨！共同推动底层视觉发展！ </h3>
				
					<h3>定制化底层视觉基础框架和理论研究 [<a href= "https://github.com/manman1995/manman1995.github.io/tree/master/img/NTU-周满.pptx" target="_blank"><span style="color:Red">PPT-updating</span></a>]</h3>
					<h3>定制化底层视觉基础框架和理论研究 (最新版) [<a href= "https://github.com/manman1995/manman1995.github.io/tree/master/img/周满-华为.pptx" target="_blank"><span style="color:Red">New</span></a>]</h3>
<!-- 				        <h3>Customized low-level vision theory [<a href= "https://github.com/manman1995/manman1995.github.io/tree/master/img/周满-华为.pptx" target="_blank"><span style="color:Red">PPT-updating</span></a>]</h3> -->
				
					       
				</p>
					<p> <span class="style8"><strong><font face="Arial"><a
              href="https://scholar.google.com/citations?user=Q65jTroAAAAJ&hl=zh-CN&oi=ao"><font color="#808080">Google Scholar Profile</font></a><font color="#808080">&nbsp;&nbsp;</font><br>
          </font></strong></span> [<a class="p1" href="https://scholar.google.com/citations?user=Q65jTroAAAAJ&hl=zh-CN&oi=ao" target="_blank">Google Scholar</a>] [<a class="p2" href="https://github.com/manman1995" target="_blank">Github</a>]</p>
		
			</td>
			<td>
				<a href="https://manzhou.github.io/"><img src="img/zm.jpg" alt="Man Zhou" border="0" width="300"></a><br>
			</td>
		</tr><tr>
	</tr>
	</tbody>
</table>
	
	 
      <h2 >News</h2>
    <div id = "news-content" style="margin-top: 15px">
	    <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.9</span>, Six papers are accepted to <strong> NeurIPS 2023 (2 spotlight)</strong></li> 
	    <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.7</span>, Awarded <a href="https://baijiahao.baidu.com/s?id=1771000026715731344&wfr=spider&for=pc"><strong> Yunfan Rising Star 2023 (云帆奖)</strong></a></li> 
	     <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.4</span>, Serving as an <strong> Area Chair for ACM MM 2023 </strong>.</li>
	      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.4</span>,  Serving as Guest editor for <strong><a href="https://www.grss-ieee.org/wp-content/uploads/2023/04/cfp_Advances-in-Satellite-Image-Quality-Enhancement-with-Deep-Learning-Techniques.pdf">IEEE JSTARS</a> </strong>.</li>
	   <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.12</span>, Awarded <a href="http://scholarship.baidu.com/home/index/index"><strong> Baidu Scholarship (百度奖学金)</strong></a></li> 	    
    </div>
     
 <tr><tr><tr><tr>
<div style="margin-top: 10px"></div>
	



     <h2>Biography</h2>
    <div id="news-content" >
	  <span> I am currently a research fellow at  Nanyang Technological University under the supervision by <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a> and <a href="https://li-chongyi.github.io/">Chongyi Li</a>. Before that, i have received my Ph.D. from  University of Science and Technology of China </a> under the supervision by <a href="http://xueyangFu.github.io">Xueyang Fu</a>, <a href="https://scholar.google.com/citations?user=vEDf62sAAAAJ&hl=zh-CN&oi=ao">Aiping Liu</a> and <a href="https://sites.google.com/view/danfeng-hong/home">Danfeng Hong</a>.
	 
          During the Phd, i was also supervised by <a href="https://gr.xjtu.edu.cn/en/web/dymeng/2;jsessionid=9E150ECA6D6A9CCD055F771E9D64A70B">Deyu Meng</a>, <a href="https://jspan.github.io/">Jinshan Pan</a> and <a href="http://www.gujinwei.org/">Jinwei Gu</a>.
	    
	  My current research interests span computer vision and machine learning with a series of topics, such as <strong><span style="color:Red">low-level vision theory</strong>, <strong><span style="color:Red">image restoration</strong>, and <strong><span style="color:Red">remote sensing image processing</strong>.</span> <br> <br> 
	  <span></span><br>
	 
	 <span style="color:blue"><strong> My research philosophy is to promote the development of customized low-level vision, so that the low-level vision can become the real low-level vision, rather than the follower of others.</strong></span>
 <span></span><br>   
	</div>
	  
	    
	    
	    
	    
</tbody>
</table>
	 


		 
		
<table id="tbPublications" width="100%">
<tbody>
<h3 style="color: red">Selected Fourier Series (傅里叶系列) </h3>
	
<tr>	
		<td><a href="" target="_blank">[.>>] Deep Fourier Up-sampling.</a><br>
		<strong>[<a href="https://github.com/manman1995/Deep-Fourier-Upsampling">Code</a>]<a href="https://openreview.net/pdf?id=NIrbtCdxfBl" style="color: blue">[PDF]</a></strong>[<a  onclick="display('DFU')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong>Man Zhou</strong>, Hu Yu, Jie Huang, Keyu Yan, Deyu Meng, Jinwei Gu, Chen Chang Loy, Chongyi Li. 
				<p ><strong><span style="color:blue">Customized up-sampling meta-operator (定制化基础算子-傅里叶上采样)</strong>. 
	       <p style="margin-top: -11px">Advances in Neural Information Processing Systems (<strong> NeurIPS (spotlight)</strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
	
<tr>	
		<td><a href="" target="_blank">	[.>>] Fourmer: An Efficient Global Modeling Paradigm for Image Restoration.</a><br>
		<p ><strong><span style="color:blue">Customized global modeling paradigm (定制化全局建模基础架构-傅里叶)</strong>. 
		<p ><strong>Man Zhou</strong>, Jie Huang, Chunle Guo, Chongyi Li. </p>
	       <p style="margin-top: -11px"><strong>ICML (oral) </strong>, 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>


<tr>	
		<td><a href="" target="_blank">[.>>] Exploring Temporal Frequency Spectrum in Deep Video Deblurring.</a><br>
			<p ><strong><span style="color:blue">Customized video meta-framework (定制化视频基础架构-傅里叶)</strong>. 
		<p >Qi Zhu, <strong>Man Zhou (corresponding author) </strong>. </p>
	       <p style="margin-top: -11px">International Conference on Computer Vision (<strong>ICCV</strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
	
<tr>	
		<td><a href="" target="_blank">[.>>] Spatial-Frequency Domain Information Integration for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/chapter/10.1007/978-3-031-19797-0_16" style="color: blue">[PDF]</a></strong>[<a  onclick="display('SFINET')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized multi-modal meta-framework (定制化多模态框架)</strong>.
			<p ><strong>Man Zhou</strong>, Jie Huang, Keyu Yan, Hu Yu, Xueyang Fu, Aiping Liu, Xian Wei, Feng Zhao. </p>
	       <p style="margin-top: -11px">European Conference on Computer Vision (<strong> ECCV </strong>), 2022. <strong>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>


<tr>	
		<td><a href="" target="_blank">[.>>]  Deep Fourier-based Exposure Correction Network with Spatial-Frequency Interaction.</a><br>
		<strong>[<a href="https://github.com/KevinJ-Huang/FECNet">Code</a>]<a href="https://link.springer.com/chapter/10.1007/978-3-031-19800-7_10" style="color: blue">[PDF]</a></strong>[<a  onclick="display('FECN')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework (定制化基础框架-傅里叶)</strong>.
			<p >Jie Huang, Yajing Liu, <strong> Man Zhou (corresponding author)</strong>, Keyu Yan, Jinghao Zhang, Yukun Huang, Feng Zhao, Zhiwei Xiong. </p>
	       <p style="margin-top: -11px">European Conference on Computer Vision (<strong> ECCV </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>



<tr>	
		<td><a href="" target="_blank">[.>>] Adaptively Learning Low-high Frequency Information Integration for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547924" style="color: blue">[PDF]</a></strong>[<a  onclick="display('AHL')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Multi-scale Fourier? Mask-crop spectrum (何为频域多尺度？- Mask-crop 频谱)</strong>. 
			<p ><strong>Man Zhou</strong>,Jie Huang, Chongyi Li, Hu Yu, Keyu Yu, Naishan Zheng, Feng Zhao </p>
	       <p style="margin-top: -11px">ACM International Conference on Multimedia (<strong> ACM MM </strong>), 2022.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="AHL" style="display: none;">
@inproceedings{zhou2022adaptively,
  title={Adaptively Learning Low-high Frequency Information Integration for Pan-sharpening},
  author={Zhou, Man and Huang, Jie and Li, Chongyi and Yu, Hu and Yan, Keyu and Zheng, Naishan and Zhao, Feng},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={3375--3384},
  year={2022}
}</pre>
</div>	



<tr>	
		<td><a href="" target="_blank">[.>>] Multi-scale Dual-domain Guidance Network for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/alexhe101/MSDDN">Code</a>]</strong><br>
		<p >Xuanhua He, Keyu Yan, Rui Li, Chengjun Xie, Jie Zhang, <strong>Man Zhou (corresponding author)</strong>, Danfeng Hong. </p>
	       <p style="margin-top: -11px"><strong> TGRS</strong>.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>



<tr>	
		<td><a href="" target="_blank">[.>>] Embedding Fourier for Ultra-High-Definition Low-Light Image Enhancement.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/article/10.1007/s11263-022-01699-1" style="color: blue">[PDF]</a></strong>[<a  onclick="display('EFH')" style="cursor:pointer;">BibTex</a>]<br>
			<p ><strong><span style="color:blue">Customized UHD meta-framework-crop/resize pyramid (定制化超大图基础框架-统一crop/resize金字塔)</strong>. 
			<p > Chongyi Li, Chunle Guo, Man Zhou, Zhexin Liang, Shangchen Zhou, Ruicheng Feng, and Chen Change Loy </p>
	       <p style="margin-top: -11px"><strong> ICLR (oral)</strong>, 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
<div>
<pre id="EFH" style="display: none;">
@article{zhou2023memory,
  title={Memory-augmented deep unfolding network for guided image super-resolution},
  author={Zhou, Man and Yan, Keyu and Pan, Jinshan and Ren, Wenqi and Xie, Qi and Cao, Xiangyong},
  journal={International Journal of Computer Vision},
  volume={131},
  number={1},
  pages={215--242},
  year={2023},
  publisher={Springer}
}</pre>
</div>



<tr>	
		<td><a href="" target="_blank">[.>>] Frequency and Spatial Dual Guidance for Image Dehazing.</a><br>
		<strong><a href="https://link.springer.com/chapter/10.1007/978-3-031-19800-7_11" style="color: blue">[PDF]</a></strong>[<a  onclick="display('ECCVFDH')" style="cursor:pointer;">BibTex</a>]<br>
		<p >Hu Yu, Naishan Zheng, <strong> Man Zhou</strong>,  Jie Huang, Zeyu Xiao, Feng Zhao. </p>
	       <p style="margin-top: -11px">European Conference on Computer Vision (<strong> ECCV </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="ECCVFDH" style="display: none;">
@inproceedings{yu2022frequency,
  title={Frequency and spatial dual guidance for image dehazing},
  author={Yu, Hu and Zheng, Naishan and Zhou, Man and Huang, Jie and Xiao, Zeyu and Zhao, Feng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIX},
  pages={181--198},
  year={2022},
  organization={Springer}
}</pre>
</div>			       

  <tr>	
		<td><a href="" target="_blank">[.>>]  Exploring Fourier Prior for Single Image Rain Removal.</a><br>
		<strong><a href="https://www.ijcai.org/proceedings/2022/0131.pdf" style="color: blue">[PDF]</a></strong>[<a  onclick="display('IJCAIF')" style="cursor:pointer;">BibTex</a>]<br>
		<p >Xin Guo, Xueyang Fu, <strong> Man Zhou</strong>,  Zhen Huang, Jialun Peng, Zhengjun Zha. </p>
	       <p style="margin-top: -11px">International Joint Conference on Artificial Intelligence (<strong> IJCAI </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="IJCAIF" style="display: none;">
@inproceedings{guo2022exploring,
  title={Exploring fourier prior for single image rain removal},
  author={Guo, Xin and Fu, Xueyang and Zhou, Man and Huang, Zhen and Peng, Jialun and Zha, Zheng-Jun},
  booktitle={Proceedings of the 30th International Joint Conferences on Artificial Intelligence},
  pages={935--941},
  year={2022}
}</pre>
</div>		
	
</tbody>
</table>



	
   		      
<table id="tbPublications" width="100%">
<tbody>
<h3 style="color: red">Image restoration (自然图像复原) </h3>	
	
	<tr>	
		<td><a href="" target="_blank">[.>>] Image De-raining via Continual Learning.</a><br>
		<strong>[<a href="https://github.com/manman1995/Image-De-raining-via-Continual-Learning">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Image_De-Raining_via_Continual_Learning_CVPR_2021_paper.html" style="color: blue">[PDF]</a></strong>[<a  onclick="display('CL')" style="cursor:pointer;">BibTex</a>]<br>
			<p ><strong><span style="color:blue">the first continual learning-based image restoration work (第一篇连续学习底层图像处理文章)</strong>. 
			<p ><strong>Man Zhou</strong>, Jie Xiao, Yifan Chang, Xueyang Fu, Aiping Liu, Jinshan Pan, Zheng-Jun Zha. </p>
	       <p style="margin-top: -11px">IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	



	
	
<tr>	
		<td><a href="" target="_blank">[.>>] Empowering Low-Light Image Enhancer through Customized Learnable Priors.</a><br>
			<p ><strong><span style="color:blue">Customized image prior (定制化先验)</strong>. 
		<p >Naishan Zheng, <strong>Man Zhou (corresponding author)</strong>. </p>
	 <p style="margin-top: -11px">International Conference on Computer Vision (<strong>ICCV</strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	


<tr>	
		<td><a href="" target="_blank">[.>>] Generalized Lightness Adaptation with Channel Selective Normalization.</a><br>
			<p ><strong><span style="color:blue">Customized operator (定制化基础算子)</strong>. 
		<p >Mingde Yao, Jie Huang, <strong>Man Zhou</strong>, Zhiwei Xiong. </p>
	 <p style="margin-top: -11px">International Conference on Computer Vision (<strong>ICCV</strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>


<tr>	
		<td><a href="" target="_blank">[.>>]  Learning Non-Uniform-Sampling for Ultra-High-Definition Image Enhancement.</a><br>
			<p ><strong><span style="color:blue">Customized framework (定制化框架)</strong>. 
		<p >Wei Yu, Jie Huang, <strong>Man Zhou</strong>. </p>
	 <p style="margin-top: -11px">ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
		       
<tr>	
		<td><a href="" target="_blank">[.>>]  Exposure-Consistency Representation Learning for Exposure Correction.</a><br>
		<strong>[<a href="https://github.com/KevinJ-Huang/ECLNet">Code</a>]<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547829" style="color: blue">[PDF]</a></strong>[<a  onclick="display('ELC')" style="cursor:pointer;">BibTex</a>]<br>
				<p ><strong><span style="color:blue">Customized meta-operator-invariant theory (定制化基础算子-阴阳理论)</strong>. 
			<p >Jie Huang, <strong> Man Zhou (co-first author)</strong>, Yajing Liu, Mingde Yao, Feng Zhao, Zhiwei Xiong. </p>
	       <p style="margin-top: -11px">ACM International Conference on Multimedia (<strong> ACM MM</strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
			
			
<tr>	
		<td><a href="" target="_blank">[.>>] Improving De-raining Generalization via Neural Reorganization.</a><br>
		<strong>[<a href="https://xueyangfu.github.io/">Code</a>]<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xiao_Improving_De-Raining_Generalization_via_Neural_Reorganization_ICCV_2021_paper.html?ref=https://githubhelp.com" style="color: blue">[PDF]</a></strong>[<a  onclick="display('ICCVNR')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">introducing brained-inspired mechanism into image processing/restoration field (神经生物学：大脑记忆机制引入底层图像处理)</strong>. </p>
			<p >Jie Xiao, <strong> Man Zhou (co-first author)</strong>, Xueyang Fu, Aiping Liu, Zheng-Jun Zha. </p>
	       <p style="margin-top: -11px">International Conference on Computer Vision (<strong> ICCV </strong>), 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>		
			

	
	
<tr>	
		<td><a href="" target="_blank">[.>>] Learning Sample Relationship for Exposure Correction.</a><br>
			<p ><strong><span style="color:blue">Customized loss (定制化损失函数)</strong>. 
		<p > Jie Huang, <strong> Man Zhou (Co-first author & corresponding author) </strong>,  Jie Xiao, kaiwen zheng, Naishan Zheng, Feng Zhao, Zhiwei Xiong </p>
			<p style="margin-top: -11px">IEEE Conference on Computer Vision and Pattern Recognition  (<strong> CVPR </strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>


	
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Memory-augmented Deep Unfolding Network for Guided Image Super-resolution.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/article/10.1007/s11263-022-01699-1" style="color: blue">[PDF]</a></strong>[<a  onclick="display('MAnet')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Information flow orthogonal to memory flow (记忆流与信号流正交)</strong>. 
			<p ><strong>Man Zhou</strong>, Keyu Yan, Jinshan Pan, Wenqi Ren, Qi Xie, Xiangyong Cao </p>
	       <p style="margin-top: -11px">International Journal of Computer Vision (<strong> IJCV </strong>), 2022.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="MAnet" style="display: none;">
@article{zhou2023memory,
  title={Memory-augmented deep unfolding network for guided image super-resolution},
  author={Zhou, Man and Yan, Keyu and Pan, Jinshan and Ren, Wenqi and Xie, Qi and Cao, Xiangyong},
  journal={International Journal of Computer Vision},
  volume={131},
  number={1},
  pages={215--242},
  year={2023},
  publisher={Springer}
}</pre>
</div>	
	
	

	
<tr>	
		<td><a href="" target="_blank">[.>>]  Deep Fourier Up-sampling.</a><br>
		<strong>[<a href="https://github.com/manman1995/Deep-Fourier-Upsampling">Code</a>]<a href="https://openreview.net/pdf?id=NIrbtCdxfBl" style="color: blue">[PDF]</a></strong>[<a  onclick="display('DFU')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized up-sampling meta-operator (定制化基础算子-傅里叶上采样)</strong>. 
			<p ><strong>Man Zhou</strong>, Hu Yu, Jie Huang, Keyu Yan, Deyu Meng, Jinwei Gu, Chen Chang Loy, Chongyi Li </p>
	       <p style="margin-top: -11px">Advances in Neural Information Processing Systems (<strong> NeurIPS (spotlight)</strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="DFU" style="display: none;">
@inproceedings{yudeep,
  title={Deep Fourier Up-Sampling},
  author={Yu, Hu and Huang, Jie and Zhao, Feng and Gu, Jinwei and Loy, Chen Change and Meng, Deyu and Li, Chongyi and others},
  booktitle={Advances in Neural Information Processing Systems}
}</pre>
</div>	
	
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Unfolding Taylor’s Approximations for Image Restoration.</a><br>
		<strong>[<a href="https://github.com/manman1995/Unfolding-Taylor-s-Approximations-for-Image-Restoration">Code</a>]<a href="https://proceedings.neurips.cc/paper/2021/file/9e3cfc48eccf81a0d57663e129aef3cb-Paper.pdf" style="color: blue">[PDF]</a></strong>[<a  onclick="display('TL')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework- a novel image processing/restoration framework (定制化基础框架-泰勒展开-新的图像处理框架)</strong>. 
			<p ><strong>Man Zhou</strong>, Zeyu Xiao, Xueyang Fu, Aiping Liu, Gang Yang, Zhiwei Xiong. </p>
	       <p style="margin-top: -11px">Thirty-fifth Conference on Neural Information Processing Systems (<strong> NeurIPS </strong>), 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="TL" style="display: none;">
@article{fu2021unfolding,
  title={Unfolding Taylor's Approximations for Image Restoration},
  author={Fu, Xueyang and Xiao, Zeyu and Yang, Gang and Liu, Aiping and Xiong, Zhiwei and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18997--19009},
  year={2021}
}</pre>
</div>	

<tr>	
		<td><a href="" target="_blank">[.>>]  Image De-raining via Continual Learning.</a><br>
		<strong>[<a href="https://github.com/manman1995/Image-De-raining-via-Continual-Learning">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Image_De-Raining_via_Continual_Learning_CVPR_2021_paper.html" style="color: blue">[PDF]</a></strong>[<a  onclick="display('CL')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">the first continual learning-based image restoration work (第一篇连续学习底层图像处理文章)</strong>. 
			<p ><strong>Man Zhou</strong>, Jie Xiao, Yifan Chang, Xueyang Fu, Aiping Liu, Jinshan Pan, Zheng-Jun Zha. </p>
	       <p style="margin-top: -11px">IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="CL" style="display: none;">
@inproceedings{zhou2021image,
  title={Image de-raining via continual learning},
  author={Zhou, Man and Xiao, Jie and Chang, Yifan and Fu, Xueyang and Liu, Aiping and Pan, Jinshan and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4907--4916},
  year={2021}
}</pre>
</div>		
			
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Learning Sample Relationship for Exposure Correction.</a><br>
			<p ><strong><span style="color:blue">Customized loss (定制化损失函数)</strong>. 
		<p > Jie Huang, <strong> Man Zhou (Co-first author & corresponding author) </strong>,  Jie Xiao, kaiwen zheng, Naishan Zheng, Feng Zhao, Zhiwei Xiong </p>
			<p style="margin-top: -11px">IEEE Conference on Computer Vision and Pattern Recognition  (<strong> CVPR </strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
	
	
	
	
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Learning Semantic Degradation-Aware Guidance for Recognition-Driven Unsupervised Low-Light Image Enhancement.</a><br>
		<p ><strong><span style="color:blue">Customized low-for-high meta-framework (定制化 Low for High 框架)</strong>. 
			<p > Naishan Zheng，Jie Huang，<strong>Man Zhou (corresponding author) </strong>, Zizheng Yang，Qi Zhu，Feng Zhao </p>
	       <p style="margin-top: -11px">Thirty-Seventh AAAI Conference on Artificial Intelligence (<strong> AAAI </strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
		       
<tr>	
		<td><a href="" target="_blank">[.>>] Deep Fourier-based Exposure Correction Network with Spatial-Frequency Interaction.</a><br>
		<strong>[<a href="https://github.com/KevinJ-Huang/FECNet">Code</a>]<a href="https://link.springer.com/chapter/10.1007/978-3-031-19800-7_10" style="color: blue">[PDF]</a></strong>[<a  onclick="display('FECN')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework (定制化基础框架-傅里叶)</strong>. 
			<p >Jie Huang, Yajing Liu, <strong> Man Zhou (corresponding author)</strong>, Keyu Yan, Jinghao Zhang, Yukun Huang, Feng Zhao, Zhiwei Xiong. </p>
	       <p style="margin-top: -11px">European Conference on Computer Vision (<strong> ECCV </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="FECN" style="display: none;">
@inproceedings{huang2022deep,
  title={Deep Fourier-Based Exposure Correction Network with Spatial-Frequency Interaction},
  author={Huang, Jie and Liu, Yajing and Zhao, Feng and Yan, Keyu and Zhang, Jinghao and Huang, Yukun and Zhou, Man and Xiong, Zhiwei},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIX},
  pages={163--180},
  year={2022},
  organization={Springer}
}</pre>
</div>	
			
			
<tr>	
		<td><a href="" target="_blank">[.>>] Random Shuffle Transformer for Image Restoration.</a><br> 
		<p >  Jie Xiao, Xueyang Fu, Man Zhou, Hongjian Liu, Zhengjun Zha. </p>
			<p style="margin-top: -11px"> (<strong> ICML </strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
			
	
		       
<tr>	
		<td><a href="" target="_blank">[.>>]  Exposure-Consistency Representation Learning for Exposure Correction.</a><br>
		<strong>[<a href="https://github.com/KevinJ-Huang/ECLNet">Code</a>]<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547829" style="color: blue">[PDF]</a></strong>[<a  onclick="display('ELC')" style="cursor:pointer;">BibTex</a>]<br>
			<p ><strong><span style="color:blue">Customized meta-operator-invariant theory (定制化基础算子-阴阳理论)</strong>. 
			<p >Jie Huang, <strong> Man Zhou (co-first author)</strong>, Yajing Liu, Mingde Yao, Feng Zhao, Zhiwei Xiong. </p>
	       <p style="margin-top: -11px">ACM International Conference on Multimedia (<strong> ACM MM</strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="ELC" style="display: none;">
@inproceedings{huang2022exposure,
  title={Exposure-Consistency Representation Learning for Exposure Correction},
  author={Huang, Jie and Zhou, Man and Liu, Yajing and Yao, Mingde and Zhao, Feng and Xiong, Zhiwei},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={6309--6317},
  year={2022}
}</pre>
</div>	
		

<tr>	
		<td><a href="" target="_blank">[.>>]  Control Theory-Inspired Model Design for Single Image De-Raining.</a><br>
		<strong>[<a href="https://github.com/manman1995">Code</a>]<a href="https://ieeexplore.ieee.org/abstract/document/9499114" style="color: blue">[PDF]</a></strong><br>
		<p ><strong><span style="color:blue">introducing control theory into image processing/restoration field (控制理论引入底层图像处理)</strong>. 
			<p ><strong>Man Zhou</strong>, Gang Yang, Keyu Yan, Aiping Liu, Xueyang Fu, Fan Wang. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Circuits and Systems II: Express Briefs, 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		

<tr>	
		<td><a href="" target="_blank">[.>>]  PID Controller-Inspired Model Design for Single Image De-raining.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://ieeexplore.ieee.org/abstract/document/9661815" style="color: blue">[PDF]</a></strong>[<a  onclick="display('PID')" style="cursor:pointer;">BibTex</a>]<br>
	               <p ><strong><span style="color:blue">introducing control theory into image processing/restoration field (控制理论引入底层图像处理)</strong>. 
			<p ><strong>Man Zhou</strong>, Fan Wang, Xian Wei, Rujing Wang, Xue Wang. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Circuits and Systems II: Express Briefs, 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="PID" style="display: none;">
@article{zhou2021pid,
  title={PID controller-inspired model design for single image de-raining},
  author={Zhou, Man and Wang, Fan and Wei, Xian and Wang, Rujing and Wang, Xue},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs},
  volume={69},
  number={4},
  pages={2351--2355},
  year={2021},
  publisher={IEEE}
}</pre>
</div>	

<tr>	
		<td><a href="" target="_blank">[.>>]  Reinforcedet: Object Detection By Integrating Reinforcement Learning With Decoupled Pipeline.</a><br>
		<p ><strong>Man Zhou</strong>, Liu Liu, Rujing Wang. </p>
	       <p style="margin-top: -11px">IEEE International Conference on Image Processing (<strong> ICIP </strong>), 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>



<tr>	
		<td><a href="" target="_blank">[.>>] ReinforceNet: A reinforcement learning embedded object detection framework with region selection network.</a><br>
		<p ><strong>Man Zhou</strong>, Rujing Wang, Chengjun Xie, Liu Liu, Rui Li, Fangyuan Wang, Dengshan Li. </p>
	       <p style="margin-top: -11px">Neurocomputing, 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>




<tr>	
		<td><a href="" target="_blank">[.>>]  SIS: A New Multi-Scale Convolutional Operator.</a><br>
		<p ><strong>Man Zhou</strong>, Xueyang Fu, Aiping Liu. </p>
	       <p style="margin-top: -11px">Journal of University of Science and Technology of China, 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Improving De-raining Generalization via Neural Reorganization.</a><br>
		<strong>[<a href="https://xueyangfu.github.io/">Code</a>]<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xiao_Improving_De-Raining_Generalization_via_Neural_Reorganization_ICCV_2021_paper.html?ref=https://githubhelp.com" style="color: blue">[PDF]</a></strong>[<a  onclick="display('ICCVNR')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">introducing brained-inspired mechanism into image processing/restoration field (神经生物学：大脑记忆机制引入底层图像处理)</strong>. </p>
			<p >Jie Xiao, <strong> Man Zhou (co-first author)</strong>, Xueyang Fu, Aiping Liu, Zheng-Jun Zha. </p>
	       <p style="margin-top: -11px">International Conference on Computer Vision (<strong> ICCV </strong>), 2021. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="ICCVNR" style="display: none;">
@inproceedings{xiao2021improving,
  title={Improving de-raining generalization via neural reorganization},
  author={Xiao, Jie and Zhou, Man and Fu, Xueyang and Liu, Aiping and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4987--4996},
  year={2021}
}</pre>
</div>	
			
			
		       </tbody>
</table>  




<table id="tbPublications" width="100%">
<tbody>
<h3 style="color: red">Remote sensing (遥感) </h3>




<tr>	
		<td><a href="" target="_blank">[.>>]  Mutual Information-driven Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/manman1995/Mutual-Information-driven-Pan-sharpening">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.pdf" style="color: blue">[PDF]</a></strong>[<a  onclick="display('MT')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework by information theory (定制化多模态基础框架-信息论)</strong>. 
			<p ><strong>Man Zhou</strong>, Keyu Yan, Xueyang Fu, Jie Huang, Zihe Yang, Feng Zhao. </p>
	       <p style="margin-top: -11px">IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2022.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Pyramid Dual Domain Injection Network for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/manman1995/Mutual-Information-driven-Pan-sharpening">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.pdf" style="color: blue">[PDF]</a></strong>[<a  onclick="display('MT')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework (空频多尺度)</strong>. 
			<p >Xuanhua He, <strong>Man Zhou (corresponding author) </strong>. </p>
	       <p style="margin-top: -11px">International Conference on Computer Vision (<strong> ICCV </strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>


<tr>	
		<td><a href="" target="_blank">[.>>]  PanFlowNet: A Flow-Based Deep Network for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/manman1995/Mutual-Information-driven-Pan-sharpening">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.pdf" style="color: blue">[PDF]</a></strong>[<a  onclick="display('MT')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework (空频多尺度)</strong>. 
			<p >Xuanhua He, Xiangyong Cao, <strong>Man Zhou</strong>, Deyu Meng, Xun Chen, Aiping Liu. </p>
	       <p style="margin-top: -11px">International Conference on Computer Vision (<strong> ICCV </strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

	

<tr>	
		<td><a href="" target="_blank">[.>>]  Learned Image Reasoning Prior Penetrates Deep Unfolding Network for Panchromatic and Multi-Spectral Image Fusion.</a><br>
		<strong>[<a href="https://github.com/manman1995">Code</a>]</strong><br>
			<p ><strong><span style="color:blue">Customized image prior (定制化先验)</strong>. 
		<p ><strong>Man Zhou</strong>. </p>
	       <p style="margin-top: -11px">International Conference on Computer Vision (<strong>ICCV</strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	

<tr>	
		<td><a href="" target="_blank">[.>>]  Learning Deep Multiscale Local Dissimilarity Prior for Pansharpening.</a><br>
		<strong>[<a href="https://github.com/manman1995">Code</a>]</strong><br>
		<p >Kai Zhang, <strong>Man Zhou</strong>. </p>
	       <p style="margin-top: -11px"><strong> TGRS</strong>, 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>			       

	
			

<tr>	
		<td><a href="" target="_blank">[.>>]  Pan-sharpening with Customized Transformer and Invertible Neural Network.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20267" style="color: blue">[PDF]</a></strong>[<a  onclick="display('AINN')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">the first transformer-based pan-sharpening work (第一篇pan-sharpening transformer 工作-跟风热点文)</strong>. 
			<p ><strong>Man Zhou</strong>, Jie Huang, Yanchi Fang, Xueyang Fu, Aiping Liu. </p>
	       <p style="margin-top: -11px">AAAI Conference on Artificial Intelligence (<strong> AAAI </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
	

	
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Memory-augmented Deep Unfolding Network for Guided Image Super-resolution.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/article/10.1007/s11263-022-01699-1" style="color: blue">[PDF]</a></strong>[<a  onclick="display('MAnet')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Information flow orthogonal to memory flow (记忆流与信号流正交)</strong>. 
			<p ><strong>Man Zhou</strong>, Keyu Yan, Jinshan Pan, Wenqi Ren, Qi Xie, Xiangyong Cao </p>
	       <p style="margin-top: -11px">International Journal of Computer Vision (<strong> IJCV </strong>), 2022.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="MAnet" style="display: none;">
@article{zhou2023memory,
  title={Memory-augmented deep unfolding network for guided image super-resolution},
  author={Zhou, Man and Yan, Keyu and Pan, Jinshan and Ren, Wenqi and Xie, Qi and Cao, Xiangyong},
  journal={International Journal of Computer Vision},
  volume={131},
  number={1},
  pages={215--242},
  year={2023},
  publisher={Springer}
}</pre>
</div>	
	
	

	
<tr>	
		<td><a href="" target="_blank">[.>>]  Deep Fourier Up-sampling.</a><br>
		<strong>[<a href="https://github.com/manman1995/Deep-Fourier-Upsampling">Code</a>]<a href="https://openreview.net/pdf?id=NIrbtCdxfBl" style="color: blue">[PDF]</a></strong>[<a  onclick="display('DFU')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized up-sampling meta-operator (定制化基础算子-傅里叶上采样)</strong>. 
			<p ><strong>Man Zhou</strong>, Hu Yu, Jie Huang, Keyu Yan, Deyu Meng, Jinwei Gu, Chen Chang Loy, Chongyi Li </p>
	       <p style="margin-top: -11px">Advances in Neural Information Processing Systems (<strong> NeurIPS (spotlight)</strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="DFU" style="display: none;">
@inproceedings{yudeep,
  title={Deep Fourier Up-Sampling},
  author={Yu, Hu and Huang, Jie and Zhao, Feng and Gu, Jinwei and Loy, Chen Change and Meng, Deyu and Li, Chongyi and others},
  booktitle={Advances in Neural Information Processing Systems}
}</pre>
</div>	
	
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Rethinking Pan-sharpening in Closed-loop Regularization.</a><br>
		<strong>[<a href="https://github.com/manman1995">Code</a>]</strong><br>
		<p ><strong>Man Zhou</strong>, Jie Huang, Feng Zhao, Danfeng Hong, Jocelyn Chanussot. </p>
	       <p style="margin-top: -11px"><strong> TNNLS</strong>, 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
	

<tr>	
		<td><a href="" target="_blank">[.>>]  Spatial-Frequency Domain Information Integration for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/chapter/10.1007/978-3-031-19797-0_16" style="color: blue">[PDF]</a></strong>[<a  onclick="display('SFINET')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized multi-modal meta-framework (定制化多模态框架)</strong>. 
			<p ><strong>Man Zhou</strong>, Jie Huang, Keyu Yan, Hu Yu, Xueyang Fu, Aiping Liu, Xian Wei, Feng Zhao </p>
	       <p style="margin-top: -11px">European Conference on Computer Vision (<strong> ECCV </strong>), 2022. <strong>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="SFINET" style="display: none;">
@inproceedings{zhou2022spatial,
  title={Spatial-frequency domain information integration for pan-sharpening},
  author={Zhou, Man and Huang, Jie and Yan, Keyu and Yu, Hu and Fu, Xueyang and Liu, Aiping and Wei, Xian and Zhao, Feng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XVIII},
  pages={274--291},
  year={2022},
  organization={Springer}
}</pre>
</div>	

	
<tr>	
		<td><a href="" target="_blank">[.>>]  Mutual Information-driven Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/manman1995/Mutual-Information-driven-Pan-sharpening">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.pdf" style="color: blue">[PDF]</a></strong>[<a  onclick="display('MT')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework by information theory (定制化多模态基础框架-信息论)</strong>. 
			<p ><strong>Man Zhou</strong>, Keyu Yan, Xueyang Fu, Jie Huang, Zihe Yang, Feng Zhao. </p>
	       <p style="margin-top: -11px">IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2022.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="MT" style="display: none;">
@inproceedings{zhou2022mutual,
  title={Mutual information-driven pan-sharpening},
  author={Zhou, Man and Yan, Keyu and Huang, Jie and Yang, Zihe and Fu, Xueyang and Zhao, Feng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1798--1808},
  year={2022}
}</pre>
</div>	
	
		

<tr>	
		<td><a href="" target="_blank">[.>>]  Effective Pan-Sharpening With Transformer and Invertible Neural Network.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20267" style="color: blue">[PDF]</a></strong>[<a  onclick="display('AAAIP')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">introducing invertible neural network into multi-modal field (可逆神经网络引入多模态图像融合领域)</strong>. 
			<p ><strong>Man Zhou</strong>, Xueyang Fu, Jie Huang, Feng Zhao, Aiping Liu, Rujing Wang. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Geoscience and Remote Sensing (<strong> TGRS </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="AAAIP" style="display: none;">
@inproceedings{zhou2022pan,
  title={Pan-sharpening with customized transformer and invertible neural network},
  author={Zhou, Man and Huang, Jie and Fang, Yanchi and Fu, Xueyang and Liu, Aiping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={3553--3561},
  year={2022}
}</pre>
</div>		

	
	
<tr>	
		<td><a href="" target="_blank">[.>>]  Panchromatic and Multispectral Image Fusion via Alternating Reverse Filtering Network.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://arxiv.org/abs/2210.08181" style="color: blue">[PDF]</a></strong>[<a  onclick="display('ZeroFilter')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">Customized meta-framework-point fixed theory (定制化基础框架-不动点方程)</strong>. 
			<p >Keyu Yan, <strong> Man Zhou (co-first author)</strong>, Jie Huang, Chengjun Xie, Feng Zhao, Chongyi Li, Danfeng Hong </p>
	       <p style="margin-top: -11px">Advances in Neural Information Processing Systems (<strong> NeurIPS (spotlight)</strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="ZeroFilter" style="display: none;">
@article{yan2022panchromatic,
  title={Panchromatic and Multispectral Image Fusion via Alternating Reverse Filtering Network},
  author={Yan, Keyu and Zhou, Man and Huang, Jie and Zhao, Feng and Xie, Chengjun and Li, Chongyi and Hong, Danfeng},
  journal={arXiv preprint arXiv:2210.08181},
  year={2022}
}</pre>
</div>	
	

		       		

<tr>	
		<td><a href="" target="_blank">[.>>]  Normalization-based Feature Selection and Restitution for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547774" style="color: blue">[PDF]</a></strong>[<a  onclick="display('Norm')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong>Man Zhou</strong>, Jie Huang, Keyu Yan, Gang Yang, Aiping Liu, Chongyi Li, Feng Zhao. 
	       <p style="margin-top: -11px">ACM International Conference on Multimedia (<strong> ACM MM </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="Norm" style="display: none;">
@inproceedings{zhou2022normalization,
  title={Normalization-based Feature Selection and Restitution for Pan-sharpening},
  author={Zhou, Man and Huang, Jie and Yan, Keyu and Yang, Gang and Liu, Aiping and Li, Chongyi and Zhao, Feng},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={3365--3374},
  year={2022}
}</pre>
</div>	
			
			

					

<tr>	
		<td><a href="" target="_blank">[.>>]  Pan-sharpening with Customized Transformer and Invertible Neural Network.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20267" style="color: blue">[PDF]</a></strong>[<a  onclick="display('AINN')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong><span style="color:blue">the first transformer-based pan-sharpening work (第一篇pan-sharpening transformer 工作-跟风热点文)</strong>. 
			<p ><strong>Man Zhou</strong>, Jie Huang, Yanchi Fang, Xueyang Fu, Aiping Liu. </p>
	       <p style="margin-top: -11px">AAAI Conference on Artificial Intelligence (<strong> AAAI </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="AINN" style="display: none;">
@inproceedings{zhou2022pan,
  title={Pan-sharpening with customized transformer and invertible neural network},
  author={Zhou, Man and Huang, Jie and Fang, Yanchi and Fu, Xueyang and Liu, Aiping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={3553--3561},
  year={2022}
}</pre>
</div>	
			

<tr>	
		<td><a href="" target="_blank">[.>>]   Memory-augmented Deep Conditional Unfolding Network for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Memory-Augmented_Deep_Conditional_Unfolding_Network_for_Pan-Sharpening_CVPR_2022_paper.html" style="color: blue">[PDF]</a></strong>[<a  onclick="display('CPS')" style="cursor:pointer;">BibTex</a>]<br>
		<p >Gang Yang, <strong> Man Zhou (co-first author)</strong>, Yajing Liu, Mingde Yao, Feng Zhao, Zhiwei Xiong. </p>
	       <p style="margin-top: -11px">IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR</strong>), 2022.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="CPS" style="display: none;">
@inproceedings{yang2022memory,
  title={Memory-augmented deep conditional unfolding network for pan-sharpening},
  author={Yang, Gang and Zhou, Man and Yan, Keyu and Liu, Aiping and Fu, Xueyang and Wang, Fan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1788--1797},
  year={2022}
}</pre>
</div>	
	

<tr>	
		<td><a href="" target="_blank">[.>>]   Deep Adaptive Pansharpening via Uncertainty-aware Image Fusion.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Memory-Augmented_Deep_Conditional_Unfolding_Network_for_Pan-Sharpening_CVPR_2022_paper.html" style="color: blue">[PDF]</a></strong>[<a  onclick="display('CPS')" style="cursor:pointer;">BibTex</a>]<br>
		<p >Kaiwen Zheng, Jie Huang, <strong> Man Zhou</strong>, Danfeng Hong, Feng Zhao. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Geoscience and Remote Sensing (<strong> TGRS </strong>), 2023.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

	
	
	
		       
<tr>	
		<td><a href="" target="_blank"> [.>>]  PAN-guided band-aware multi-spectral feature enhancement for Pan-sharpening.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/article/10.1007/s11263-022-01699-1" style="color: blue">[PDF]</a></strong><br>
		<p ><strong>Man Zhou</strong>, Keyu Yan, Aiping Liu, Chengjun Xie, Xueyang Fu. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Computational Imaging (<strong> TCI </strong>), 2023. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
			

<tr>	
		<td><a href="" target="_blank">[.>>]  Effective Pan-sharpening by Multi-Scale Invertible Neural Network and Heterogeneous Task Distilling.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://ieeexplore.ieee.org/abstract/document/9858176" style="color: blue">[PDF]</a></strong><br>
		<p ><strong>Man Zhou</strong>, Jie Huang, Feng Zhao, Xueyang Fu, Danfeng Hong. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Geoscience and Remote Sensing (<strong> TGRS </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	      
<tr>	
		<td><a href="" target="_blank">[.>>]  Effective Pan-sharpening by Multi-Scale Invertible Neural Network and Heterogeneous Task Distilling.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/article/10.1007/s11263-022-01699-1" style="color: blue">[PDF]</a></strong>[<a  onclick="display('KD')" style="cursor:pointer;">BibTex</a>]<br>
		<p ><strong> Man Zhou </strong>, Jie Huang, Xueyang Fu, Feng Zhao, Danfeng Hong. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Geoscience and Remote Sensing (<strong> TGRS </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="KD" style="display: none;">
@article{zhou2022effective,
  title={Effective pan-sharpening by multiscale invertible neural network and heterogeneous task distilling},
  author={Zhou, Man and Huang, Jie and Fu, Xueyang and Zhao, Feng and Hong, Danfeng},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--14},
  year={2022},
  publisher={IEEE}
}</pre>
</div>	


<tr>	
		<td><a href="" target="_blank">[.>>]  Memory-Augmented Model-Driven Network for Pansharpening.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://link.springer.com/chapter/10.1007/978-3-031-19800-7_18" style="color: blue">[PDF]</a></strong>[<a  onclick="display('MAEnet')" style="cursor:pointer;">BibTex</a>]<br>
		<p >Keyu Yan, <strong>Man Zhou (co-first author)</strong>, Li Zhang, Chengjun Xie. </p>
	       <p style="margin-top: -11px">European Conference on Computer Vision (<strong> ECCV </strong>), 2022. 
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
<div>
<pre id="MAEnet" style="display: none;">
@inproceedings{yan2022memory,
  title={Memory-Augmented Model-Driven Network for Pansharpening},
  author={Yan, Keyu and Zhou, Man and Zhang, Li and Xie, Chengjun},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIX},
  pages={306--322},
  year={2022},
  organization={Springer}
}</pre>
</div>			


<tr>	
		<td><a href="" target="_blank">[.>>]  When Pan-sharpening Meets Graph Convolution Network and Knowledge Distillation.</a><br>
		<strong>[<a href="https://github.com/Man-Zhou-ustc/pansharpening">Code</a>]<a href="https://ieeexplore.ieee.org/abstract/document/9758796" style="color: blue">[PDF]</a></strong>[<a  onclick="display('Graph')" style="cursor:pointer;">BibTex</a>]<br>
		<p > Keyu Yan, <strong>Man Zhou (co-first author)</strong>, Liu Liu, Chengjun Xie, Danfeng Hong. </p>
	       <p style="margin-top: -11px">IEEE Transactions on Geoscience and Remote Sensing (<strong> TGRS </strong>), 2022.
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>		
<div>
<pre id="Graph" style="display: none;">
@article{yan2022pansharpening,
  title={When pansharpening meets graph convolution network and knowledge distillation},
  author={Yan, Keyu and Zhou, Man and Liu, Liu and Xie, Chengjun and Hong, Danfeng},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--15},
  year={2022},
  publisher={IEEE}
}</pre>
</div>	
			
			
		       </tbody>
</table>  














	 
  
   
    <h2>Industrial Experience</h2>
	<ul>
	<li>
		<div style="float:left; text-align:left">Shanghai, AI Lab. </div> <div style="float:right; text-align:right">Mar. 2022 – Present</div><br>
		Research Intern<br>
		Topic: Image restoration<br>
	</li>
	
	</ul>  
	 
	 
      <h2><strong>Academic Experience:Reviewer</strong></h2>
   <div>
	<strong>Journal Reviewers:</strong> 
	  TPAMI, IJCV, TNNLS, TGRS, 
	  Neurocomputing, etc.<br>
	   
	 <strong>Conference PC/Reviewers:</strong> CVPR, ECCV, AAAI, ICCV, NeurIPS, ICML, etc.<br>
    </div>
	
	 

	
	  
	  
	  
	  

     <div id="footer">
	<div id="footer-text"></div>
    </div>
    <div id = "logo" style="margin-top: 10px; text-align:center">
	    <div align="center" style="margin:auto;padding-top:10px">
            <div style="width:12%">
               <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=vsfhxeJwKLZUtBh0-nJF19SAlWMC-tAJQ9LvMyPKpog&cl=ffffff&w=a"></script>
            </div>
           <br>
        &copy; Man Zhou | <span style="color:Red">Last updated: March 01, 2022</span>
            </div>
     </div>     
    
  </div>

</body></html>
